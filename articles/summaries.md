https://www.sciencedirect.com/science/article/pii/S0957417418303579Links to an external site.
- In this paper they look at a new fraud detection method for payment cards that combines dynamic random forest with k-nearest neighbors.
- The system focuses on preventing expensive fraud losses rather than just focusing on accuracy.
- It preformed better than traditional models and reduced fraud losses by about 23% by paying more attention to recent transactions and taking into account that behavior changes over time.
https://www.tandfonline.com/doi/10.1080/08839514.2024.2385249#abstractLinks to an external site.
- In this paper they focus on using decision tree algorithms to detect credit card fraud by looking at two large datasets
- In the study they found that transaction amount and merchant name are the most important features when it comes to identifying fraud
- They emphasize how decision trees are accurate as well as interpretable, which makes them useful for real time fraud detection
https://www.mdpi.com/2227-7390/9/21/2683Links to an external site.
This paper proposes AE-PRF which is a credit card fraud detection method that uses an auto encoder first and then applies a probabilistic random forest in order to classify whether the transactions are fraudulent. Models typically struggle with extreme data imbalance between normal and fraudulent transactions, which can be seen in the kaggle dataset in the article. AE-PRF achieved very high accuracy and a strong correlation coefficient as well as reaching a true positive rate of about 0.89. It was able to show that it can handle imbalanced data and outperform competing methods.
https://www.nature.com/articles/s41598-025-00873-yLinks to an external site.
This paper looks at a machine learning approach to detecting credit card fraud that uses Synthetic Minority Over Sampling Techniques as well as random forests to balance a highly imbalanced dataset. Traditional rule based methods cannot adapt quickly so this is good for being able to adapt as credit card fraud techniques grow and being able to be scalable and accurate. Among the tested algorithms, random forest model performed the best and showed a strong ability to identify fraud and limit false positives.
https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/epdf/10.1002/cem.873Links to an external site.
This article teaches how to use decision trees for classification and regression and explains how decision trees split data. It looks at algorithms like CART and C4.5 and describes multivariate and probabilistic extensions. They emphasize the strengths of decision trees, like interpretability and flexibility, while noting their sensitivity to small data changes and typically lower predictive accuracy than modern ensemble methods. 
https://journals.mesopotamian.press/index.php/BJML/article/view/417/289Links to an external site.
In this article, random forest is introduced as a method where many decision trees are built on bootstrap samples and random subsets of features, whose outputs are combined by majority vote for classification or averaging for regression. It explains how random forests are based on CART decision trees and reduce overfitting and handles high-dimensional, noisy, or incomplete data.

